# Repository Cleanup Plan for Thesis Reproducibility

## Summary
This document identifies files to **KEEP** (essential for reproducibility) and **DELETE** (temporary/redundant).

---

## âœ… FILES TO KEEP

### 1. Configuration Files (Root)
- âœ… `docker-compose.yml` - Neo4j Fabric cluster setup
- âœ… `README.md` - Will be rewritten in Task 3

### 2. Benchmark Properties Files (ldbc_snb_interactive_v2_impls/cypher/driver/)
**Essential (Used in thesis experiments):**
- âœ… `benchmark-pathA.properties` - Read-only thread sweep (Experiment 1)
- âœ… `benchmark-overhead-fabric.properties` - Coordinator overhead via Fabric (Experiment 2)
- âœ… `benchmark-overhead-direct.properties` - Coordinator overhead direct (Experiment 2)
- âœ… `benchmark-mixed-deletes.properties` - Mixed workload with deletes (Experiment 3)
- âœ… `benchmark-mixed-cleanup.properties` - Cleanup-aware deletes (Experiment 4)

**To DELETE (redundant/unused):**
- âŒ `benchmark.properties` - Generic template
- âŒ `benchmark.properties.temp` - Temporary
- âŒ `benchmark-test.properties` - Test file
- âŒ `benchmark-pathB.properties` - Relaxed schedule experiment (not completed)
- âŒ `benchmark-mixed.properties` - Superseded by benchmark-mixed-deletes.properties

### 3. PowerShell/Python Scripts (scripts/)
**Essential:**
- âœ… `consistency_checks.ps1` - Pre/post benchmark consistency validation
- âœ… `extract_query_latencies.py` - Thesis data extraction
- âœ… `run_mixed_deletes.ps1` - Run mixed workload experiment
- âœ… `run_mixed_cleanup.ps1` - Run cleanup-aware experiment
- âœ… `backup-sharded-database.sh` - Database backup utility
- âœ… `restore-sharded-database.sh` - Database restore utility

**To DELETE (redundant/intermediate):**
- âŒ `run_benchmark.ps1` - Generic runner, superseded
- âŒ `run_mixed_with_consistency.ps1` - Superseded by run_mixed_deletes.ps1
- âŒ `run_pathA.ps1` - Can be replaced with direct java command
- âŒ `run_set_sharded.sh` - Old test script
- âŒ `compare_sharded_vs_baseline.ps1` - Analysis script, not needed for reproduction
- âŒ `generate_summary_metrics.ps1` - Analysis script, not needed for reproduction
- âŒ `parse_ldbc_results.ps1` - Superseded by extract_query_latencies.py
- âŒ `parse_neo4j_querylogs.ps1` - Analysis script
- âŒ `docker_stats_sampler.ps1` - Monitoring script, not essential
- âŒ `restart_cold.ps1` - Test utility
- âŒ `scripts/D/` directory - Appears to be accidental duplicate
- âŒ `.benchmark_temp_*.properties` files - Temporary benchmark configs
- âŒ `.tmp_results_*/` directories - Temporary result directories

### 4. Cypher Data Loading Files (Root & scripts/)
**Essential:**
- âœ… `load-persons-data-sf1-complete.cypher` - Final persons shard data loader
- âœ… `load-forums-data-sf1-complete.cypher` - Final forums shard data loader

**To DELETE (test/old versions):**
- âŒ `load-persons-data-sf1.cypher` - Superseded by -complete version
- âŒ `load-persons-data-sf1-test.cypher` - Test version
- âŒ `load-persons-data-v2.cypher` - Old version
- âŒ `load-forums-data-sf1.cypher` - Superseded by -complete version
- âŒ `load-forums-data-sf1-test.cypher` - Test version
- âŒ `load-forums-data-sf1-minimal.cypher` - Test version
- âŒ `load-forums-data-sf1-forums-only.cypher` - Partial loader
- âŒ `load-forums-data-v2.cypher` - Old version
- âŒ `load-posts-comments-fixed.cypher` - Old fix attempt
- âŒ `load-forum-members.cypher` - Partial loader
- âŒ `scripts/load-persons-data.cypher` - Duplicate
- âŒ `scripts/load-forums-data.cypher` - Duplicate

### 5. Cypher Query Files (ldbc_snb_interactive_v2_impls/cypher/queries/)
**Essential:**
- âœ… Keep all `interactive-complex-*.cypher` files (standard LDBC queries)
- âœ… Keep all `interactive-delete-*.cypher` files (delete operations)
- âœ… Keep all `interactive-insert-*.cypher` files (insert operations)
- âœ… Keep all `interactive-short-*.cypher` files (short reads)
- âœ… `interactive-complex-11-direct.cypher` - Direct-to-shard version for overhead experiment

**Note:** The `queries-direct/` directory should be kept if it contains modified queries for overhead experiment.

### 6. Results & Analysis (results/)
**Essential (Thesis data):**
- âœ… `THESIS_CONSISTENCY_ANALYSIS.md` - Consistency experiment analysis
- âœ… `THESIS_COORDINATOR_OVERHEAD_ANALYSIS.md` - Overhead experiment analysis
- âœ… `THESIS_COORDINATOR_OVERHEAD_TABLE.csv` - Overhead data table
- âœ… `THESIS_COORDINATOR_OVERHEAD_LATEX.txt` - LaTeX formatted results
- âœ… `THESIS_SUMMARY_TABLE.csv` - Overall summary
- âœ… `THESIS_LATEX_TABLE.txt` - LaTeX formatted summary
- âœ… `THESIS_QUERY_LATENCIES_SUMMARY.md` - Query latency analysis
- âœ… `query_latencies_for_boxplot.csv` - Extracted latency data
- âœ… `pathA_*_console.log` - Path A benchmark logs (1, 2, 4 threads)
- âœ… `overhead_fabric_console.log` - Overhead experiment log
- âœ… `overhead_direct_console.log` - Overhead experiment log
- âœ… `mixed_deletes_*_console.log` - Mixed workload logs (final run)
- âœ… `mixed_cleanup_*_console.log` - Cleanup experiment logs (final run)
- âœ… `LDBC-SNB-*-results.json` - Final LDBC result files
- âœ… `LDBC-SNB-*-results_log.csv` - Final LDBC logs
- âœ… `consistency_index.csv` - Consistency check index

**To DELETE (intermediate/old runs):**
- âŒ `results/sharded/raw/*` - Old test runs (keep only final documented runs)
- âŒ Multiple duplicate log files from early testing
- âŒ `manual_recording_template.csv` - Template, not needed

### 7. Temporary/Generated Files (Root)
**To DELETE:**
- âŒ `barplot.png` - Analysis output
- âŒ `benchmark_results.csv` - Intermediate results
- âŒ `inconsistency_log.csv` - Superseded by results in results/
- âŒ `temp_analysis/` - All temporary analysis files
- âŒ `temp_q10.txt` - Temporary
- âŒ `temp_q11.txt` - Temporary
- âŒ `logs/` - Can be regenerated

### 8. Submodules/Large Directories (DO NOT DELETE - Will be in .gitignore)
- âœ… `ldbc_snb_interactive_v2_driver/` - LDBC driver (will be cloned by setup script)
- âœ… `ldbc_snb_interactive_v2_impls/` - LDBC implementations (will be cloned by setup script)
- âœ… `backups/` - Database backups
- âœ… `ldbc_snb_interactive_v2_impls/ldbc-snb-sf1/` - Dataset (will be downloaded by setup script)

---

## ğŸ“ SUMMARY

### Files to Keep: ~40-50 essential files
- 1 docker-compose.yml
- 5 benchmark properties files
- 6-7 essential scripts
- 2 data loading scripts
- All query files in queries/ directory
- ~10-15 key result/analysis files

### Files to Delete: ~100+ redundant files
- 5 redundant benchmark properties
- 10+ old/duplicate scripts
- 10+ old data loading scripts
- Temporary analysis files
- Old test run logs
- Duplicate files

---

## ğŸ¯ RECOMMENDED FINAL STRUCTURE

```
neo4j-fabric-project/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ README.md
â”œâ”€â”€ setup_environment.sh               [NEW - Task 2]
â”œâ”€â”€ .gitignore                         [Updated]
â”‚
â”œâ”€â”€ ldbc_snb_interactive_v2_driver/    [Cloned by setup script]
â”œâ”€â”€ ldbc_snb_interactive_v2_impls/     [Cloned by setup script]
â”‚   â””â”€â”€ cypher/
â”‚       â”œâ”€â”€ driver/
â”‚       â”‚   â”œâ”€â”€ benchmark-pathA.properties
â”‚       â”‚   â”œâ”€â”€ benchmark-overhead-fabric.properties
â”‚       â”‚   â”œâ”€â”€ benchmark-overhead-direct.properties
â”‚       â”‚   â”œâ”€â”€ benchmark-mixed-deletes.properties
â”‚       â”‚   â””â”€â”€ benchmark-mixed-cleanup.properties
â”‚       â””â”€â”€ queries/
â”‚           â”œâ”€â”€ interactive-complex-*.cypher
â”‚           â”œâ”€â”€ interactive-delete-*.cypher
â”‚           â”œâ”€â”€ interactive-insert-*.cypher
â”‚           â””â”€â”€ interactive-complex-11-direct.cypher
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ consistency_checks.ps1
â”‚   â”œâ”€â”€ extract_query_latencies.py
â”‚   â”œâ”€â”€ run_mixed_deletes.ps1
â”‚   â”œâ”€â”€ run_mixed_cleanup.ps1
â”‚   â”œâ”€â”€ backup-sharded-database.sh
â”‚   â”œâ”€â”€ restore-sharded-database.sh
â”‚   â”œâ”€â”€ load-persons-data-sf1-complete.cypher
â”‚   â””â”€â”€ load-forums-data-sf1-complete.cypher
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ THESIS_CONSISTENCY_ANALYSIS.md
â”‚   â”œâ”€â”€ THESIS_COORDINATOR_OVERHEAD_ANALYSIS.md
â”‚   â”œâ”€â”€ THESIS_QUERY_LATENCIES_SUMMARY.md
â”‚   â”œâ”€â”€ *.csv (key data files)
â”‚   â”œâ”€â”€ *.log (final experiment logs)
â”‚   â””â”€â”€ *.json (LDBC results)
â”‚
â””â”€â”€ backups/                           [In .gitignore]
    â”œâ”€â”€ neo4j-data-forums-backup.tar.gz
    â”œâ”€â”€ neo4j-data-main-backup.tar.gz
    â””â”€â”€ neo4j-data-persons-backup.tar.gz
```

---

## âš ï¸ BEFORE PROCEEDING

**Question for user:** 
1. Did you complete an unsharded baseline benchmark? If so, where are those files?
2. Which exact SF1 dataset did you download? (Need URL for setup script)
3. Should I keep `pathA_8threads_console.log` even though it failed? (For documentation)
4. Any other specific result files you want to preserve?

